
# --- Django ---
DJANGO_SETTINGS_MODULE=openmoxie.settings
DEBUG=False
SECRET_KEY=XzcpBHwZF2eAeKhLMNd71I1hvYWcBfP8eaNpHA7YRGHB6tBOjxjS6YJ2SqPt8X5P

# --- Allowed hosts (optional override) ---
# ALLOWED_HOSTS=localhost,127.0.0.1

# --- Provider defaults ---
LLM_PROVIDER=openai
# OLLAMA_MODEL=llama3.2:3b

# Use the Ollama container by default (service name "ollama")
OLLAMA_HOST=http://ollama:11434
# If you run Ollama on the HOST instead of the container, use one of the following:
#   Mac/Windows (Docker Desktop):  OLLAMA_HOST=http://host.docker.internal:11434
#   Linux (docker bridge):         OLLAMA_HOST=http://172.17.0.1:11434

# --- Local STT  ---
STT_BACKEND=local
STT_URL=http://stt:8001/stt
STT_LANG=es
# The STT container controls its own model/device/compute via docker-compose (not this file).

# --- MQTT (service name inside Compose) ---
MQTT_HOST=mqtt
MQTT_PORT=8883

# --- API keys (uncomment if you switch providers) ---
OPENAI_API_KEY=sk-...
# XAI_API_KEY=...